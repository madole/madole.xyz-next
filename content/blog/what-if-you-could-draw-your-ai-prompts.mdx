---
title: 'What if You Could Draw Your AI Prompts?'
date: '2025-07-31T10:54:57.304Z'
tags: ['ai','agents','agentic workflows','tools']
slug: 'what-if-you-could-draw-your-ai-prompts'
description: "Discover a more intuitive way to talk to AI. This guide explores TLDraw's Computer, a tool that lets you sketch your prompts and make abstract ideas tangible."
og_image: "/blog-images/what-if-you-could-draw/og-image.png"
---

![TLDraw Computer](/blog-images/what-if-you-could-draw/og-image.png)

Working with AI can often feel complex, abstract and impenetrable. 

> What is all this jargon?"
>
> "How do I even get started?

But what if interacting with AI models was more intuitive, fun even? 

That's exactly what TLDraw's experimental AI tool does. It bridges the gap between abstract AI concepts and tangible, visual interactions. 

Lets look at how TLDraw's 'Computer' can transform your understanding of AI, allowing you to sketch out ideas and bring them to life by easily employing AI models.

## What is TLDraw?

It's kind of two things. It's a toolkit for developers to build their own whiteboards. But if you're not building whiteboards into your app, it's a simple, free-to-use webapp [tldraw.com](https://tldraw.com) for sketching out ideas. 

It's perfect for brainstorming, brain dumping and general visual thinking and it gives Excalidraw a run for its money, although I love [Excalidraw](https://excalidraw.com) too.

## Thinking visually with TLDraw's Computer

This is where things get really interesting. TLDraw's AI experiment, ['TLDraw Computer'](https://computer.tldraw.com), 
lets you move beyond classic text prompts and instead _sketch_ your ideas directly on the infinite canvas.

Imagine drawing shapes, adding text labels, and then 'talking' to an AI model to make those visual elements perform actions. 


This tool introduces a totally different way of interacting with AI, turning AI concepts naturally into something you can see and interact with. 
You almost forget AI is in the picture at all. 


Don't be surprised if your early experiments result in delightfully chaotic 'Rube Goldberg' machinesâ€”that's a huge part of the fun. 
It's this playful, hands-on approach that proves so effective for getting a real feel for what AI is good at and what it's not.


## How does it actually work?

It's a really simple back-and-forth. You start by drawing your idea on the canvas, maybe a couple of boxes with an arrow between them and some text explaining the rules. 

The AI then analyzes everything you've laid out to understand your instructions. 

Finally, it brings your idea to life by moving things around, generating text, images, or even speech. 

Hit play, see if it works, if its not quite right, tweak it and try again. 


![core loop image](/blog-images/what-if-you-could-draw/workflow.png)

Its a pretty simple yet powerful workflow that enables rapid prototyping and iterative design, turning your static sketch into a live, interactive program.

## Example: Building a knock knock joke machine

Let's build something fun to see how this works: a 'Knock Knock Joke Machine'.

Imagine drawing two text fields on the canvas. 

You label one 'Joke theme' and the other 'Joke'. Between them, you draw an arrow pointing from the input to the output through an instruction box which holds the AI instruction. 

For our joke machine, this 'Instruction' box would contain something like this:

> You are an amazing comedian who specializes in knock-knock jokes. You take a theme [theme] and create a hilarious knock-knock joke on this theme.

_Bigging the AI up a bit seems to make it do a better job. "You're so amazing...."_

Now, when you type a theme into your 'Joke theme' text field (e.g., 'Animals', 'Food', 'Space'), the AI processes this. Based on your instruction, it generates a complete knock-knock joke related to that theme and populates it directly into your 'Joke' text field.


## Lets do it
Lets add the text box for the input


![Input box image](/blog-images/what-if-you-could-draw/input-box.png)

Then the instruction box with our crafted instruction


![Instruction box image](/blog-images/what-if-you-could-draw/instruction.png)

Then we add a text box for the joke to go into


![joke box image](/blog-images/what-if-you-could-draw/joke-box.png)

Then we'll run it with the input "clock".


![joke image](/blog-images/what-if-you-could-draw/run-the-joke.png)

Now lets have some fun, lets see if it can produce an image from the joke


![image image](/blog-images/what-if-you-could-draw/image.png)

As you use the tool, you get these fun sparks of "what if", and its so frictionless to test-the-water of your crazy idea, you end up giving them a go at a much higher rate than any other AI tool I've used. 

When you think about it, this kind of visual programming allows for a much more intuitive understanding of how prompts work and how AI models consume and produce information.

## Go draw something

[TLDraw Computer](https://computer.tldraw.com) may be an experiment, but it's a fun one with real potential. 

It has helped me a lot with understanding agentic workflows and how to think about them. Its also sparked a lot of fun ideas. 

Go give it a crack and see what you can come up with when the power of AI is as accessible as a box of crayons and a blank sheet of paper. 
