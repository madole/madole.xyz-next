---
title: 'Six things about how AI is changing software engineering'
date: '2025-11-30T10:00:00.000Z'
tags: ['AI','software engineering','GenAI','engineering leadership']
slug: 'six-things-about-how-ai-is-changing-software-engineering'
---

Some Sunday morning thoughts on where we're at in the software engineering industry with the prevalence of Generative AI. I have many more thoughts on this topic but here are a few of them considering where we are at right now in November 2025.

- AI is enabling engineers to work above their skill level. This is a double edge sword as engineers get stuck less often, and with the right mindset and process they can accelerate their learning journey, but in other cases where imposter syndrome is present, it's allowing engineers to appear competent but actually lack part of a skillset, confidence or self-awareness. Instead of asking for help from a colleague, they can yeet generated code that appears to be _good_ into a codebase yet have no understanding behind it. You might detect this if the engineer lashes out and gets defensive out during routine code review questioning as they attempt to cover their path, it's your job as a leader to employ empathy and guide them through this to a better path.
- Being able to get to a correct solution quickly is a good short term win for the business and scrum team but in my experience, learning and wisdom happens during the 50 wrong doors you knocked on attempting to get to the right answer. You learn not only the way to solve the problem, but all the ways this particular problem isn't solved and how other adjacent problems could be solved. This can potentially be offset by much deeper learning in a single problem space rather the shallower but broad learning of exploring all the incorrect paths.
- Engineering tasks that used to take weeks or months like late-stage internationalising an application are now a prompt and a bit of babysitting an agent away. This a very promising win from my perspective. It's low complexity but tedious and very suited to entry level agentic work.
- With AI tools like V0, Lovable, Google AI studio and even Figma's built-in AI tools, the days of an engineer getting a pretty figma design to implement that has broken UX should be behind us because we should be able to test the UX in a prototype environment with a few prompts and the time it takes to make a coffee, to ensure that the design doesn't just look good, it actually functions for the user as well.
- Agentic tools like Claude Code are incredibly powerful in the hands of someone who knows what "good" looks like. You can craft a team of agents that do technical design, implementation, code review, QA, and even release notes all autonomously. And then run them in parallel on different work trees or branches. That's a lot of code being generated, it takes quite a while to develop the skillset to stay across the code to ensure quality is being generated and to step in and fix or redirect as needed. The traditional path to getting to a position of knowing what "good" looks like (typically a senior engineer) was fairly linear before GenAI. Be a junior, pair program a lot, take on small tasks, receive feedback and iterate. Next move to a mid level role and refine your craft by taking on more and more complexity before moving to senior and thinking bigger and more about how systems hang together, while mentoring and pairing with the junior/mids so the cycle continues. I think the jury is still out on how that path is affected in the world of GenAI. I think junior engineers will be more AI native that those that came before so their ability to prompt engineer and context engineer will come very naturally but the skills to validate the code generated will need acquired.
- The playing field is very uneven at the minute. Those who can afford the time to develop the skills to interact with these tools are winning over those that dont. Those who are more senior and know what good software looks like are able to capitalise on using these tools whereas juniors coming out of uni might feel like the ladder is being pulled up in front of them. Companies that can afford to pay for the latest models at high usage levels in team plans with commercial agreements have an advantage over those who can't. This will probably even out over time as inference costs reduce, models get smarter and the industry adapts and provides pathways and expectations for engineers to progress through the system being AI enabled but not required.
